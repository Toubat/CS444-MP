{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Part 1A Introduction: Multi-label Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_submission import output_submission_csv\n",
    "from classifier import SimpleClassifier, Classifier#, AlexNet\n",
    "from voc_dataloader import VocDataset, VOC_CLASSES\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Classification\n",
    "In this assignment, you train a classifier to do multi-label classificaton on the PASCAL VOC 2007 dataset. The dataset has 20 different class which can appear in any given image. Your classifier will predict whether each class appears in an image. This task is slightly different from exclusive multiclass classification like the ImageNet competition where only a single most appropriate class is predicted for an image.\n",
    "\n",
    "## Part 1A\n",
    "You will use this notebook to warm up with pytorch and the code+dataset that we will use for assignment3. \n",
    "\n",
    "### What to do\n",
    "In part 1A, You are asked to run below experiments. You don't need to change hyperparameters for this Part 1A's experiments. (the following code provides everything that you will need.)\n",
    "1. to train a simple network (defined in ```classifiers.py```) \n",
    "2. to train the AlexNet (PyTorch built-in) \n",
    "    - from scratch \n",
    "    - finetuning AlexNet pretrained on ImageNet\n",
    "\n",
    "\n",
    "    \n",
    "### What to submit\n",
    "We ask you to run the following code and report the results in your homework submission. You may want to leverage this part 1A get yourself familiar with PyTorch.\n",
    "\n",
    "You will the need the numbers and plots this notebook outputs for reports, but you are not required to submit this notebook as a printed pdf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Pascal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we will load the training data and also apply some transforms to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms applied to the training data\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std= [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = VocDataset('VOCdevkit_2007/VOC2007/','train',train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the test data for the PASCAL VOC 2007 dataset. Do __NOT__ add data augmentation transforms to validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms applied to the testing data\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = VocDataset('VOCdevkit_2007/VOC2007/','val',test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data\n",
    "\n",
    "PASCAL VOC has bounding box annotations in addition to class labels. Use the following code to visualize some random examples and corresponding annotations from the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    idx = np.random.randint(0, len(ds_train.names)+1)\n",
    "    _imgpath = os.path.join('VOCdevkit_2007/VOC2007/', 'JPEGImages', ds_train.names[idx]+'.jpg')\n",
    "    img = Image.open(_imgpath).convert('RGB')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for j in range(len(ds_train.box_indices[idx])):\n",
    "        obj = ds_train.box_indices[idx][j]\n",
    "        draw.rectangle(list(obj), outline=(255,0,0))\n",
    "        draw.text(list(obj[0:2]), ds_train.classes[ds_train.label_order[idx][j]], fill=(0,255,0))\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(np.array(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare what device to use: gpu/cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(train_loader, classifier, criterion, optimizer):\n",
    "    classifier.train()\n",
    "    loss_ = 0.0\n",
    "    losses = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    return torch.stack(losses).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n",
    "    classifier.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        y_true = np.zeros((0,21))\n",
    "        y_score = np.zeros((0,21))\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = classifier(images)\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
    "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "        aps = []\n",
    "        # ignore first class which is background\n",
    "        for i in range(1, y_true.shape[1]):\n",
    "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "            if print_ind_classes:\n",
    "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
    "            aps.append(ap)\n",
    "        \n",
    "        mAP = np.mean(aps)\n",
    "        test_loss = np.mean(losses)\n",
    "        if print_total:\n",
    "            print('mAP: {0:.4f}'.format(mAP))\n",
    "            print('Avg loss: {}'.format(test_loss))\n",
    "        \n",
    "    return mAP, test_loss, aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functions\n",
    "def plot_losses(train, val, test_frequency, num_epochs):\n",
    "    plt.plot(train, label=\"train\")\n",
    "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
    "    plt.plot(indices, val, label=\"val\")\n",
    "    plt.title(\"Loss Plot\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mAP(train, val, test_frequency, num_epochs):\n",
    "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
    "    plt.plot(indices, train, label=\"train\")\n",
    "    plt.plot(indices, val, label=\"val\")\n",
    "    plt.title(\"mAP Plot\")\n",
    "    plt.ylabel(\"mAP\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network \n",
    "\n",
    "The simple network you are given as is will allow you to reach around 0.15-0.2 mAP. In this project, you will find ways to design a better network. Save plots and final test mAP scores as you will be adding these to the writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n",
    "    train_losses = []\n",
    "    train_mAPs = []\n",
    "    val_losses = []\n",
    "    val_mAPs = []\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        print(\"Starting epoch number \" + str(epoch))\n",
    "        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
    "        if(epoch%test_frequency==0 or epoch==1):\n",
    "            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n",
    "            train_mAPs.append(mAP_train)\n",
    "            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
    "            print('Evaluating classifier')\n",
    "            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
    "            val_losses.append(val_loss)\n",
    "            val_mAPs.append(mAP_val)\n",
    "    \n",
    "    return classifier, train_losses, val_losses, train_mAPs, val_mAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier().to(device)\n",
    "# You can can use this function to reload a network you have already saved previously\n",
    "#classifier.load_state_dict(torch.load('voc_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the Classifier\n",
    "num_epochs = 20\n",
    "test_frequency = 5\n",
    "\n",
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare train and validation metrics\n",
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clssifier network\n",
    "# Suggestion: you can save checkpoints of your network during training and reload them later\n",
    "torch.save(classifier.state_dict(), './voc_simple_classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = VocDataset('VOCdevkit_2007/VOC2007test/','test', test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1)\n",
    "\n",
    "# Transforms applied to the testing data\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('my_solution.csv', test_aps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Baselines (From Scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet was one of the earliest deep learning models to have success in classification. In this section we will be running classification with AlexNet as a baseline. Furthermore, we will run an ImageNet-pretrained AlexNet to observe the impact of well-trained features. Save plots and final test mAP scores as you will be adding these to the writeup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running AlexNet\n",
    "\n",
    "In this section, we train AlexNet from scratch using the same hyperparameters as our previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "test_frequency = 5\n",
    "\n",
    "# Change classifier to AlexNet\n",
    "classifier = torchvision.models.alexnet(pretrained=False)\n",
    "classifier.classifier._modules['6'] = nn.Linear(4096, 21)   \n",
    "classifier = classifier.to(device)\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
    "print(\"Test mAP: \", mAP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice somewhat poor performance. You could try running AlexNet with an Adam optimizer instead with learning rate 1e-4 to see if that makes a difference. This experiment is not required for the writeup, but it may show you the importance of a good learning rate and optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the impact of pretrained features. This model's weights were trained on ImageNet, which is a much larger dataset. How do pretrained features perform on VOC? Why do you think there is such a large difference in performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "test_frequency = 5\n",
    "\n",
    "# Load Pretrained AlexNet\n",
    "classifier = torchvision.models.alexnet(pretrained=True)\n",
    "classifier.classifier._modules['6'] = nn.Linear(4096, 21)   \n",
    "classifier = classifier.to(device)\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
    "print(\"Test mAP: \", mAP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
