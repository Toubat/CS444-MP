{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS444 Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from kaggle_submission import output_submission_csv\n",
    "from models.neural_net import NeuralNetwork\n",
    "from utils.data_process import get_FASHION_data\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # set default size of plots\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Fashion-MNIST\n",
    "Now that you have implemented a neural network that passes gradient checks and works on toy data, you will test your network on the Fashion-MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change these numbers for experimentation\n",
    "# For submission be sure they are set to the default values\n",
    "TRAIN_IMAGES = 50000\n",
    "VAL_IMAGES = 10000\n",
    "TEST_IMAGES = 10000\n",
    "\n",
    "data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, TEST_IMAGES)\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "X_val, y_val = data['X_val'], data['y_val']\n",
    "X_test, y_test = data['X_test'], data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using SGD\n",
    "To train our network we will use SGD. In addition, we will adjust the learning rate with an exponential learning rate schedule as optimization proceeds; after each epoch, we will reduce the learning rate by multiplying it by a decay rate.\n",
    "\n",
    "You can try different numbers of layers and other hyperparameters on the Fashion-MNIST dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_layers, hidden_size, learning_rate, reg_const, opt = \"SGD\", log = False):\n",
    "    global X_train, y_train, X_val, y_val\n",
    "    \n",
    "    epochs = 80\n",
    "    input_size = 28 * 28\n",
    "    num_classes = 10\n",
    "    batch_size = 200\n",
    "    learning_rate_decay = 0.95\n",
    "    hidden_sizes = [hidden_size] * (num_layers - 1)\n",
    "    \n",
    "    # Initialize a new neural network model\n",
    "    net = NeuralNetwork(input_size, hidden_sizes, num_classes, num_layers)\n",
    "\n",
    "    # Variables to store performance for each epoch\n",
    "    train_loss = np.zeros(epochs)\n",
    "    train_accuracy = np.zeros(epochs)\n",
    "    val_accuracy = np.zeros(epochs)\n",
    "\n",
    "    # For each epoch...\n",
    "    for epoch in range(epochs):    \n",
    "        # Shuffle the dataset\n",
    "        indices = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        \n",
    "        # Training\n",
    "        # For each mini-batch...\n",
    "        for batch in range(TRAIN_IMAGES // batch_size):\n",
    "            # Create a mini-batch of training data and labels\n",
    "            X_batch = X_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "            y_batch = y_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "            \n",
    "            # Run the forward pass of the model to get a prediction and compute the accuracy\n",
    "            score = net.forward(X_batch)\n",
    "            y_pred = np.argmax(score, axis=1)\n",
    "            train_accuracy[epoch] += (y_pred == y_batch).sum()\n",
    "\n",
    "            # Run the backward pass of the model to compute the loss, and update the weights\n",
    "            loss = net.backward(y_batch, reg_const)\n",
    "            train_loss[epoch] += loss\n",
    "\n",
    "            net.update(lr=learning_rate, opt=opt)\n",
    "\n",
    "        train_accuracy[epoch] /= TRAIN_IMAGES\n",
    "\n",
    "        if log:\n",
    "            print(f'Epoch {epoch + 1}/{epochs}: loss = {loss:.4f}, accuracy = {train_accuracy[epoch]:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        # No need to run the backward pass here, just run the forward pass to compute accuracy\n",
    "        score = net.forward(X_val)\n",
    "        y_pred = np.argmax(score, axis=1)\n",
    "\n",
    "        val_accuracy[epoch] += (y_pred == y_val).sum() / len(y_val)\n",
    "        \n",
    "        # Implement learning rate decay\n",
    "        learning_rate *= learning_rate_decay\n",
    "    \n",
    "    return train_loss, train_accuracy, val_accuracy, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(net):\n",
    "    y_test_pred = np.argmax(net.forward(X_test), axis=1)\n",
    "    y_val_pred = np.argmax(net.forward(X_val), axis=1)\n",
    "\n",
    "    test_acc = (y_test_pred == y_test).sum() / len(y_test)\n",
    "    val_acc = (y_val_pred == y_val).sum() / len(y_val)\n",
    "\n",
    "    return val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_acc, net = train(3, 32, 1e-3, 0.2, \"SGD\", True)\n",
    "get_acc(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using Adam\n",
    "Next we will train the same model using the Adam optimizer. You should take the above code for SGD and modify it to use Adam instead. For implementation details, see the lecture slides. The original paper that introduced Adam is also a good reference, and contains suggestions for default values: https://arxiv.org/pdf/1412.6980.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: loss = 0.4675, accuracy = 0.7738\n",
      "Epoch 2/100: loss = 0.3804, accuracy = 0.8555\n",
      "Epoch 3/100: loss = 0.3977, accuracy = 0.8697\n",
      "Epoch 4/100: loss = 0.4118, accuracy = 0.8754\n",
      "Epoch 5/100: loss = 0.3129, accuracy = 0.8803\n",
      "Epoch 6/100: loss = 0.3279, accuracy = 0.8856\n",
      "Epoch 7/100: loss = 0.2653, accuracy = 0.8902\n",
      "Epoch 8/100: loss = 0.2629, accuracy = 0.8910\n",
      "Epoch 9/100: loss = 0.2791, accuracy = 0.8952\n",
      "Epoch 10/100: loss = 0.2697, accuracy = 0.8966\n",
      "Epoch 11/100: loss = 0.2949, accuracy = 0.8999\n",
      "Epoch 12/100: loss = 0.2392, accuracy = 0.9005\n",
      "Epoch 13/100: loss = 0.2146, accuracy = 0.9021\n",
      "Epoch 14/100: loss = 0.3038, accuracy = 0.9052\n",
      "Epoch 15/100: loss = 0.2889, accuracy = 0.9067\n",
      "Epoch 16/100: loss = 0.2260, accuracy = 0.9072\n",
      "Epoch 17/100: loss = 0.2161, accuracy = 0.9106\n",
      "Epoch 18/100: loss = 0.2156, accuracy = 0.9101\n",
      "Epoch 19/100: loss = 0.2444, accuracy = 0.9122\n",
      "Epoch 20/100: loss = 0.2375, accuracy = 0.9136\n",
      "Epoch 21/100: loss = 0.1653, accuracy = 0.9136\n",
      "Epoch 22/100: loss = 0.1690, accuracy = 0.9137\n",
      "Epoch 23/100: loss = 0.1632, accuracy = 0.9163\n",
      "Epoch 24/100: loss = 0.2067, accuracy = 0.9167\n",
      "Epoch 25/100: loss = 0.2070, accuracy = 0.9176\n",
      "Epoch 26/100: loss = 0.2167, accuracy = 0.9178\n",
      "Epoch 27/100: loss = 0.2210, accuracy = 0.9191\n",
      "Epoch 28/100: loss = 0.2117, accuracy = 0.9201\n",
      "Epoch 29/100: loss = 0.2174, accuracy = 0.9212\n",
      "Epoch 30/100: loss = 0.2854, accuracy = 0.9215\n",
      "Epoch 31/100: loss = 0.2070, accuracy = 0.9224\n",
      "Epoch 32/100: loss = 0.2672, accuracy = 0.9219\n",
      "Epoch 33/100: loss = 0.2525, accuracy = 0.9238\n",
      "Epoch 34/100: loss = 0.1996, accuracy = 0.9241\n",
      "Epoch 35/100: loss = 0.2016, accuracy = 0.9241\n",
      "Epoch 36/100: loss = 0.2150, accuracy = 0.9247\n",
      "Epoch 37/100: loss = 0.2512, accuracy = 0.9267\n",
      "Epoch 38/100: loss = 0.1887, accuracy = 0.9262\n",
      "Epoch 39/100: loss = 0.2677, accuracy = 0.9268\n",
      "Epoch 40/100: loss = 0.2215, accuracy = 0.9271\n",
      "Epoch 41/100: loss = 0.2586, accuracy = 0.9273\n",
      "Epoch 42/100: loss = 0.2508, accuracy = 0.9273\n",
      "Epoch 43/100: loss = 0.2439, accuracy = 0.9275\n",
      "Epoch 44/100: loss = 0.1941, accuracy = 0.9288\n",
      "Epoch 45/100: loss = 0.2178, accuracy = 0.9289\n",
      "Epoch 46/100: loss = 0.1669, accuracy = 0.9279\n",
      "Epoch 47/100: loss = 0.2112, accuracy = 0.9298\n",
      "Epoch 48/100: loss = 0.1952, accuracy = 0.9302\n",
      "Epoch 49/100: loss = 0.1948, accuracy = 0.9299\n",
      "Epoch 50/100: loss = 0.1740, accuracy = 0.9298\n",
      "Epoch 51/100: loss = 0.2134, accuracy = 0.9303\n",
      "Epoch 52/100: loss = 0.1900, accuracy = 0.9294\n",
      "Epoch 53/100: loss = 0.2975, accuracy = 0.9308\n",
      "Epoch 54/100: loss = 0.1779, accuracy = 0.9309\n",
      "Epoch 55/100: loss = 0.1579, accuracy = 0.9315\n",
      "Epoch 56/100: loss = 0.1643, accuracy = 0.9310\n",
      "Epoch 57/100: loss = 0.1537, accuracy = 0.9312\n",
      "Epoch 58/100: loss = 0.1348, accuracy = 0.9320\n",
      "Epoch 59/100: loss = 0.1972, accuracy = 0.9327\n",
      "Epoch 60/100: loss = 0.2058, accuracy = 0.9312\n",
      "Epoch 61/100: loss = 0.1434, accuracy = 0.9322\n",
      "Epoch 62/100: loss = 0.2663, accuracy = 0.9318\n",
      "Epoch 63/100: loss = 0.1532, accuracy = 0.9320\n",
      "Epoch 64/100: loss = 0.1793, accuracy = 0.9325\n",
      "Epoch 65/100: loss = 0.2174, accuracy = 0.9324\n",
      "Epoch 66/100: loss = 0.1334, accuracy = 0.9331\n",
      "Epoch 67/100: loss = 0.1855, accuracy = 0.9322\n",
      "Epoch 68/100: loss = 0.2100, accuracy = 0.9329\n",
      "Epoch 69/100: loss = 0.2766, accuracy = 0.9327\n",
      "Epoch 70/100: loss = 0.2569, accuracy = 0.9332\n",
      "Epoch 71/100: loss = 0.2189, accuracy = 0.9327\n",
      "Epoch 72/100: loss = 0.2413, accuracy = 0.9341\n",
      "Epoch 73/100: loss = 0.2095, accuracy = 0.9336\n",
      "Epoch 74/100: loss = 0.2181, accuracy = 0.9336\n",
      "Epoch 75/100: loss = 0.1834, accuracy = 0.9339\n",
      "Epoch 76/100: loss = 0.1674, accuracy = 0.9340\n",
      "Epoch 77/100: loss = 0.1710, accuracy = 0.9340\n",
      "Epoch 78/100: loss = 0.1316, accuracy = 0.9340\n",
      "Epoch 79/100: loss = 0.2289, accuracy = 0.9335\n",
      "Epoch 80/100: loss = 0.1827, accuracy = 0.9334\n",
      "Epoch 81/100: loss = 0.2063, accuracy = 0.9337\n",
      "Epoch 82/100: loss = 0.1524, accuracy = 0.9336\n",
      "Epoch 83/100: loss = 0.1430, accuracy = 0.9338\n",
      "Epoch 84/100: loss = 0.1255, accuracy = 0.9345\n",
      "Epoch 85/100: loss = 0.1755, accuracy = 0.9340\n",
      "Epoch 86/100: loss = 0.2173, accuracy = 0.9345\n",
      "Epoch 87/100: loss = 0.2054, accuracy = 0.9344\n",
      "Epoch 88/100: loss = 0.1672, accuracy = 0.9343\n",
      "Epoch 89/100: loss = 0.1273, accuracy = 0.9339\n",
      "Epoch 90/100: loss = 0.1880, accuracy = 0.9338\n",
      "Epoch 91/100: loss = 0.2286, accuracy = 0.9346\n",
      "Epoch 92/100: loss = 0.2164, accuracy = 0.9337\n",
      "Epoch 93/100: loss = 0.1946, accuracy = 0.9351\n",
      "Epoch 94/100: loss = 0.2121, accuracy = 0.9341\n",
      "Epoch 95/100: loss = 0.1726, accuracy = 0.9347\n",
      "Epoch 96/100: loss = 0.1605, accuracy = 0.9341\n",
      "Epoch 97/100: loss = 0.2220, accuracy = 0.9347\n",
      "Epoch 98/100: loss = 0.2190, accuracy = 0.9346\n",
      "Epoch 99/100: loss = 0.1866, accuracy = 0.9352\n",
      "Epoch 100/100: loss = 0.2219, accuracy = 0.9351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8868, 0.8781)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_acc, val_acc, net = train(3, 32, 0.001, 0.2, \"Adam\", True)\n",
    "get_acc(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph loss and train/val accuracies\n",
    "\n",
    "Examining the loss graph along with the train and val accuracy graphs should help you gain some intuition for the hyperparameters you should try in the hyperparameter tuning below. It should also help with debugging any issues you might have with your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and train / validation accuracies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Once you have successfully trained a network you can tune your hyparameters to increase your accuracy.\n",
    "\n",
    "Based on the graphs of the loss function above you should be able to develop some intuition about what hyperparameter adjustments may be necessary. A very noisy loss implies that the learning rate might be too high, while a linearly decreasing loss would suggest that the learning rate may be too low. A large gap between training and validation accuracy would suggest overfitting due to a large model without much regularization. No gap between training and validation accuracy would indicate low model capacity. \n",
    "\n",
    "You will compare networks of two and three layers using the different optimization methods you implemented. \n",
    "\n",
    "The different hyperparameters you can experiment with are:\n",
    "- **Batch size**: We recommend you leave this at 200 initially which is the batch size we used. \n",
    "- **Number of iterations**: You can gain an intuition for how many iterations to run by checking when the validation accuracy plateaus in your train/val accuracy graph.\n",
    "- **Initialization** Weight initialization is very important for neural networks. We used the initialization `W = np.random.randn(n) / sqrt(n)` where `n` is the input dimension for layer corresponding to `W`. We recommend you stick with the given initializations, but you may explore modifying these. Typical initialization practices: http://cs231n.github.io/neural-networks-2/#init\n",
    "- **Learning rate**: Generally from around 1e-4 to 1e-1 is a good range to explore according to our implementation.\n",
    "- **Learning rate decay**: We recommend a 0.95 decay to start.\n",
    "- **Hidden layer size**: You should explore up to around 120 units per layer. For three-layer network, we fixed the two hidden layers to be the same size when obtaining the target numbers. However, you may experiment with having different size hidden layers.\n",
    "- **Regularization coefficient**: We recommend trying values in the range 0 to 0.1. \n",
    "\n",
    "Hints:\n",
    "- After getting a sense of the parameters by trying a few values yourself, you will likely want to write a few for-loops to traverse over a set of hyperparameters.\n",
    "- If you find that your train loss is decreasing, but your train and val accuracy start to decrease rather than increase, your model likely started minimizing the regularization term. To prevent this you will need to decrease the regularization coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 20, learning_rate = 1e-05 | val_acc = 0.8242, test_acc = 0.8166\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 20, learning_rate = 0.0001 | val_acc = 0.8688, test_acc = 0.8578\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 20, learning_rate = 0.001 | val_acc = 0.8765, test_acc = 0.8698\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 20, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 20, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 32, learning_rate = 1e-05 | val_acc = 0.8206, test_acc = 0.8188\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 32, learning_rate = 0.0001 | val_acc = 0.8719, test_acc = 0.866\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 32, learning_rate = 0.001 | val_acc = 0.884, test_acc = 0.8762\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 32, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 32, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 48, learning_rate = 1e-05 | val_acc = 0.8254, test_acc = 0.8237\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 48, learning_rate = 0.0001 | val_acc = 0.8755, test_acc = 0.8671\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 48, learning_rate = 0.001 | val_acc = 0.886, test_acc = 0.8777\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 48, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 48, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 64, learning_rate = 1e-05 | val_acc = 0.8271, test_acc = 0.8194\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 64, learning_rate = 0.0001 | val_acc = 0.8749, test_acc = 0.8664\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 64, learning_rate = 0.001 | val_acc = 0.8863, test_acc = 0.8815\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 64, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 64, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8348, test_acc = 0.8256\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8763, test_acc = 0.8706\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8931, test_acc = 0.8868\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8291, test_acc = 0.8255\n",
      "num_layers = 2, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8796, test_acc = 0.871\n",
      "num_layers = 2, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8934, test_acc = 0.889\n",
      "num_layers = 2, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8297, test_acc = 0.8229\n",
      "num_layers = 2, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8771, test_acc = 0.8692\n",
      "num_layers = 2, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8917, test_acc = 0.8889\n",
      "num_layers = 2, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8295, test_acc = 0.8239\n",
      "num_layers = 2, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8746, test_acc = 0.8705\n",
      "num_layers = 2, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8909, test_acc = 0.8879\n",
      "num_layers = 2, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8325, test_acc = 0.8252\n",
      "num_layers = 2, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8776, test_acc = 0.869\n",
      "num_layers = 2, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8946, test_acc = 0.8915\n",
      "num_layers = 2, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 2, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8315, test_acc = 0.8262\n",
      "num_layers = 2, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8804, test_acc = 0.8743\n",
      "num_layers = 2, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8896, test_acc = 0.8886\n",
      "num_layers = 2, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8879, test_acc = 0.8821\n",
      "num_layers = 2, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8644, test_acc = 0.8591\n",
      "num_layers = 2, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8338, test_acc = 0.8282\n",
      "num_layers = 2, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8803, test_acc = 0.8752\n",
      "num_layers = 2, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8931, test_acc = 0.8908\n",
      "num_layers = 2, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8853, test_acc = 0.8844\n",
      "num_layers = 2, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8681, test_acc = 0.8643\n",
      "num_layers = 2, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8325, test_acc = 0.8284\n",
      "num_layers = 2, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8807, test_acc = 0.8738\n",
      "num_layers = 2, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8945, test_acc = 0.8896\n",
      "num_layers = 2, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8884, test_acc = 0.8843\n",
      "num_layers = 2, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8629, test_acc = 0.8531\n",
      "num_layers = 2, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8333, test_acc = 0.8264\n",
      "num_layers = 2, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8793, test_acc = 0.8732\n",
      "num_layers = 2, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.896, test_acc = 0.8907\n",
      "num_layers = 2, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8881, test_acc = 0.8883\n",
      "num_layers = 2, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8634, test_acc = 0.8574\n",
      "num_layers = 2, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.833, test_acc = 0.8264\n",
      "num_layers = 2, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8773, test_acc = 0.8754\n",
      "num_layers = 2, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8959, test_acc = 0.8924\n",
      "num_layers = 2, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8886, test_acc = 0.8859\n",
      "num_layers = 2, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8606, test_acc = 0.852\n",
      "num_layers = 3, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8287, test_acc = 0.8221\n",
      "num_layers = 3, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8796, test_acc = 0.8736\n",
      "num_layers = 3, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8885, test_acc = 0.8903\n",
      "num_layers = 3, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.0, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8243, test_acc = 0.8198\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8773, test_acc = 0.8736\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8929, test_acc = 0.8846\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.0955, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8243, test_acc = 0.8198\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8773, test_acc = 0.8736\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8929, test_acc = 0.8846\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.0955, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.01, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8315, test_acc = 0.8248\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8789, test_acc = 0.8737\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8917, test_acc = 0.8882\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8315, test_acc = 0.8248\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8789, test_acc = 0.8737\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8917, test_acc = 0.8882\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.05, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8277, test_acc = 0.8221\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8796, test_acc = 0.8767\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.892, test_acc = 0.8904\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8277, test_acc = 0.8221\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8796, test_acc = 0.8767\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.892, test_acc = 0.8904\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.1, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8291, test_acc = 0.8265\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8835, test_acc = 0.873\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8923, test_acc = 0.89\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8291, test_acc = 0.8265\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8835, test_acc = 0.873\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8923, test_acc = 0.89\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = SGD, reg_const = 0.2, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.1023, test_acc = 0.1\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8313, test_acc = 0.8288\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8837, test_acc = 0.8809\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8911, test_acc = 0.8871\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8871, test_acc = 0.8818\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.0955, test_acc = 0.1\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8313, test_acc = 0.8288\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8837, test_acc = 0.8809\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8911, test_acc = 0.8871\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8871, test_acc = 0.8818\n",
      "num_layers = 3, opt = Adam, reg_const = 0.0, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.0955, test_acc = 0.1\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8351, test_acc = 0.8323\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8795, test_acc = 0.875\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8934, test_acc = 0.8877\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8869, test_acc = 0.8864\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.0955, test_acc = 0.1\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8351, test_acc = 0.8323\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8795, test_acc = 0.875\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8934, test_acc = 0.8877\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8869, test_acc = 0.8864\n",
      "num_layers = 3, opt = Adam, reg_const = 0.01, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.0955, test_acc = 0.1\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.838, test_acc = 0.8301\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8851, test_acc = 0.8793\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8927, test_acc = 0.8867\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8922, test_acc = 0.8841\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.852, test_acc = 0.8455\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.838, test_acc = 0.8301\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8851, test_acc = 0.8793\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8927, test_acc = 0.8867\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8922, test_acc = 0.8841\n",
      "num_layers = 3, opt = Adam, reg_const = 0.05, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.852, test_acc = 0.8455\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.838, test_acc = 0.83\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8861, test_acc = 0.8798\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8953, test_acc = 0.8911\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8901, test_acc = 0.8846\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8482, test_acc = 0.836\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.838, test_acc = 0.83\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8861, test_acc = 0.8798\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8953, test_acc = 0.8911\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8901, test_acc = 0.8846\n",
      "num_layers = 3, opt = Adam, reg_const = 0.1, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8482, test_acc = 0.836\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8352, test_acc = 0.834\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8823, test_acc = 0.8792\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8927, test_acc = 0.8918\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8875, test_acc = 0.8843\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8562, test_acc = 0.8513\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 1e-05 | val_acc = 0.8352, test_acc = 0.834\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.0001 | val_acc = 0.8823, test_acc = 0.8792\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.001 | val_acc = 0.8927, test_acc = 0.8918\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.01 | val_acc = 0.8875, test_acc = 0.8843\n",
      "num_layers = 3, opt = Adam, reg_const = 0.2, hidden_size = 100, learning_rate = 0.1 | val_acc = 0.8562, test_acc = 0.8513\n",
      "Training complete...\n"
     ]
    }
   ],
   "source": [
    "reg_consts = [0.0, 0.01, 0.05, 0.1, 0.2]\n",
    "hidden_sizes = [20, 32, 48, 64, 100]\n",
    "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "# Train the model for each combination of hyperparameters\n",
    "for num_layers in [2, 3]:\n",
    "    for opt in [\"SGD\", \"Adam\"]:\n",
    "        for reg_const in reg_consts:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                for learning_rate in learning_rates:\n",
    "                    file_name = f'checkpoints/{num_layers}_{opt}_{reg_const}_{hidden_size}_{learning_rate}.npy'\n",
    "                    if os.path.exists(file_name):\n",
    "                        input_size = 28 * 28\n",
    "                        num_classes = 10\n",
    "                        hidden_sizes = [hidden_size] * (num_layers - 1)\n",
    "                        \n",
    "                        # Initialize a new neural network model\n",
    "                        net = NeuralNetwork(input_size, hidden_sizes, num_classes, num_layers)\n",
    "                        net.load_checkpoint(file_name)\n",
    "                    else:\n",
    "                        train_loss, train_acc, val_acc, net = train(num_layers, hidden_size, learning_rate, reg_const, opt)\n",
    "                        net.save_checkpoint(file_name)\n",
    "\n",
    "                    val_acc, test_acc = get_acc(net)\n",
    "                    accuracies[(num_layers, opt, reg_const, hidden_size, learning_rate)] = (val_acc, test_acc)\n",
    "                    print(f'num_layers = {num_layers}, opt = {opt}, reg_const = {reg_const}, hidden_size = {hidden_size}, ' +\n",
    "                        f'learning_rate = {learning_rate} | val_acc = {val_acc}, test_acc = {test_acc}')\n",
    "\n",
    "print(\"Training complete...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 'SGD'): ((2, 'SGD', 0.2, 100, 0.001), 0.8915),\n",
       " (2, 'Adam'): ((2, 'Adam', 0.2, 100, 0.001), 0.8924),\n",
       " (3, 'SGD'): ((3, 'SGD', 0.1, 100, 0.001), 0.8904),\n",
       " (3, 'Adam'): ((3, 'Adam', 0.2, 100, 0.001), 0.8918)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_accuracies = {}\n",
    "\n",
    "for num_layers in [2, 3]:\n",
    "    for opt in [\"SGD\", \"Adam\"]:\n",
    "        highest_test_acc = 0\n",
    "        highest_params = None\n",
    "\n",
    "        for reg_const in reg_consts:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                for learning_rate in learning_rates:\n",
    "                    if accuracies[(num_layers, opt, reg_const, hidden_size, learning_rate)][1] > highest_test_acc:\n",
    "                        highest_test_acc = accuracies[(num_layers, opt, reg_const, hidden_size, learning_rate)][1]\n",
    "                        highest_params = (num_layers, opt, reg_const, hidden_size, learning_rate)\n",
    "        best_test_accuracies[(num_layers, opt)] = (highest_params, highest_test_acc)\n",
    "best_test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_prediction(hyper_params):\n",
    "    global X_test\n",
    "\n",
    "    num_layers, opt, reg_const, hidden_size, learning_rate = hyper_params\n",
    "    file_name = f'checkpoints/{num_layers}_{opt}_{reg_const}_{hidden_size}_{learning_rate}.npy'\n",
    "\n",
    "    input_size = 28 * 28\n",
    "    num_classes = 10\n",
    "    hidden_sizes = [hidden_size] * (num_layers - 1)\n",
    "    \n",
    "    # Initialize a new neural network model\n",
    "    net = NeuralNetwork(input_size, hidden_sizes, num_classes, num_layers)\n",
    "    net.load_checkpoint(file_name)\n",
    "    score = net.forward(X_test)\n",
    "    y_pred = np.argmax(score, axis=1)\n",
    "\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on the test set\n",
    "When you are done experimenting, you should evaluate your final trained networks on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8915, 0.8904, 0.8924, 0.8918)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_2layer_sgd_prediction = get_test_prediction(best_test_accuracies[(2, \"SGD\")][0])\n",
    "best_3layer_sgd_prediction = get_test_prediction(best_test_accuracies[(3, \"SGD\")][0])\n",
    "best_2layer_adam_prediction = get_test_prediction(best_test_accuracies[(2, \"Adam\")][0])\n",
    "best_3layer_adam_prediction = get_test_prediction(best_test_accuracies[(3, \"Adam\")][0])\n",
    "\n",
    "best_test_accuracies[(2, \"SGD\")][1], best_test_accuracies[(3, \"SGD\")][1], best_test_accuracies[(2, \"Adam\")][1], best_test_accuracies[(3, \"Adam\")][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle output\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy, output a file to submit your test set predictions to the Kaggle for Assignment 2 Neural Network. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('./nn_2layer_sgd_submission.csv', best_2layer_sgd_prediction)\n",
    "output_submission_csv('./nn_3layer_sgd_submission.csv', best_2layer_sgd_prediction)\n",
    "output_submission_csv('./nn_2layer_adam_submission.csv', best_2layer_sgd_prediction)\n",
    "output_submission_csv('./nn_3layer_adam_submission.csv', best_2layer_sgd_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare SGD and Adam\n",
    "Create graphs to compare training loss and validation accuracy between SGD and Adam. The code is similar to the above code, but instead of comparing train and validation, we are comparing SGD and Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
